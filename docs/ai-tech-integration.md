# AI æŠ€æœ¯é›†æˆæ–¹æ¡ˆ

## ç›®å½•

- [AI åŠŸèƒ½æ¶æ„](#ai-åŠŸèƒ½æ¶æ„)
- [AI è¾…åŠ©ç¼–ç¨‹](#ai-è¾…åŠ©ç¼–ç¨‹)
- [AI æ™ºèƒ½æ•™å­¦](#ai-æ™ºèƒ½æ•™å­¦)
- [AI å†…å®¹ç”Ÿæˆ](#ai-å†…å®¹ç”Ÿæˆ)
- [AI æ¨¡å‹è®­ç»ƒå¹³å°](#ai-æ¨¡å‹è®­ç»ƒå¹³å°)
- [AI èƒ½åŠ›è¯„ä¼°](#ai-èƒ½åŠ›è¯„ä¼°)
- [æŠ€æœ¯å®ç°æ–¹æ¡ˆ](#æŠ€æœ¯å®ç°æ–¹æ¡ˆ)

## AI åŠŸèƒ½æ¶æ„

### æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       ç”¨æˆ·å±‚                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  å­¦ç”Ÿç«¯  â”‚  æ•™å¸ˆç«¯  â”‚  å®¶é•¿ç«¯  â”‚  ç®¡ç†ç«¯                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AI åº”ç”¨å±‚                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  AI ç¼–ç¨‹åŠ©æ‰‹  â”‚  æ™ºèƒ½æ•™å­¦  â”‚  AI åˆ›ä½œ  â”‚  èƒ½åŠ›è¯„ä¼°      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AI æœåŠ¡å±‚                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LLM æœåŠ¡  â”‚  CV æœåŠ¡  â”‚  NLP æœåŠ¡  â”‚  æ¨èæœåŠ¡        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AI æ¨¡å‹å±‚                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  GPT-4  â”‚  BERT  â”‚  YOLO  â”‚  è‡ªç ”æ¨¡å‹  â”‚  ç¬¬ä¸‰æ–¹ API    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    åŸºç¡€è®¾æ–½å±‚                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  GPU é›†ç¾¤  â”‚  å‘é‡æ•°æ®åº“  â”‚  æ¨¡å‹ä»“åº“  â”‚  ç›‘æ§ç³»ç»Ÿ      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒ AI æ¨¡å—

#### 1. AI ç¼–ç¨‹åŠ©æ‰‹
- ä»£ç è¡¥å…¨
- ä»£ç è§£é‡Š
- Bug æ£€æµ‹
- ä»£ç ä¼˜åŒ–å»ºè®®
- æ™ºèƒ½çº é”™

#### 2. æ™ºèƒ½æ•™å­¦ç³»ç»Ÿ
- ä¸ªæ€§åŒ–å­¦ä¹ è·¯å¾„
- æ™ºèƒ½æ¨é¢˜
- è‡ªåŠ¨æ‰¹æ”¹
- å­¦æƒ…åˆ†æ
- è™šæ‹ŸåŠ©æ•™

#### 3. AI åˆ›ä½œå·¥å…·
- AI ç»˜ç”»
- AI éŸ³ä¹
- AI å†™ä½œ
- ä»£ç ç”Ÿæˆ

#### 4. èƒ½åŠ›è¯„ä¼°ç³»ç»Ÿ
- ç¼–ç¨‹èƒ½åŠ›è¯„ä¼°
- AI ç´ å…»è¯„ä¼°
- å­¦ä¹ è¡Œä¸ºåˆ†æ
- èƒ½åŠ›ç”»åƒ

---

## AI è¾…åŠ©ç¼–ç¨‹

### åŠŸèƒ½è®¾è®¡

#### 1. ä»£ç è¡¥å…¨ï¼ˆCode Completionï¼‰

##### å®ç°æ–¹æ¡ˆ

**æ–¹æ¡ˆ Aï¼šé›†æˆç¬¬ä¸‰æ–¹æœåŠ¡**

ä½¿ç”¨ OpenAI Codex / GitHub Copilot API

```javascript
// å‰ç«¯é›†æˆç¤ºä¾‹ï¼ˆMonaco Editor + OpenAI APIï¼‰
import * as monaco from 'monaco-editor';
import { Configuration, OpenAIApi } from 'openai';

const configuration = new Configuration({
  apiKey: process.env.OPENAI_API_KEY,
});
const openai = new OpenAIApi(configuration);

// æ³¨å†Œä»£ç è¡¥å…¨æä¾›å™¨
monaco.languages.registerCompletionItemProvider('python', {
  async provideCompletionItems(model, position) {
    const textUntilPosition = model.getValueInRange({
      startLineNumber: 1,
      startColumn: 1,
      endLineNumber: position.lineNumber,
      endColumn: position.column,
    });

    try {
      const response = await openai.createCompletion({
        model: 'code-davinci-002',
        prompt: textUntilPosition,
        max_tokens: 100,
        temperature: 0.2,
      });

      const completion = response.data.choices[0].text;

      return {
        suggestions: [{
          label: completion,
          kind: monaco.languages.CompletionItemKind.Snippet,
          insertText: completion,
        }]
      };
    } catch (error) {
      console.error('AI completion error:', error);
      return { suggestions: [] };
    }
  }
});
```

**æ–¹æ¡ˆ Bï¼šè‡ªéƒ¨ç½²å¼€æºæ¨¡å‹**

ä½¿ç”¨ CodeGenã€StarCoder ç­‰å¼€æºæ¨¡å‹

```python
# åç«¯ API ç¤ºä¾‹ï¼ˆFastAPI + Hugging Faceï¼‰
from fastapi import FastAPI
from transformers import AutoTokenizer, AutoModelForCausalLM

app = FastAPI()

# åŠ è½½æ¨¡å‹
model_name = "bigcode/starcoder"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)

@app.post("/api/code-completion")
async def code_completion(code: str, language: str):
    inputs = tokenizer.encode(code, return_tensors="pt")
    outputs = model.generate(
        inputs,
        max_length=inputs.shape[1] + 100,
        temperature=0.2,
        pad_token_id=tokenizer.eos_token_id
    )
    
    completion = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return {"completion": completion[len(code):]}
```

##### ä¼˜åŒ–ç­–ç•¥

- **ç¼“å­˜æœºåˆ¶**ï¼šç¼“å­˜å¸¸è§è¡¥å…¨ç»“æœ
- **æœ¬åœ°æ¨ç†**ï¼šä½¿ç”¨ ONNX.js æœ¬åœ°è¿è¡Œå°æ¨¡å‹
- **æ··åˆæ–¹æ¡ˆ**ï¼šæœ¬åœ°å°æ¨¡å‹ + äº‘ç«¯å¤§æ¨¡å‹
- **å»¶è¿Ÿä¼˜åŒ–**ï¼šé¢„æµ‹æ€§è¡¥å…¨ã€å¢é‡æ›´æ–°

---

#### 2. ä»£ç è§£é‡Šï¼ˆCode Explanationï¼‰

##### åŠŸèƒ½è®¾è®¡

- **é€è¡Œè§£é‡Š**ï¼šè§£é‡Šæ¯è¡Œä»£ç çš„ä½œç”¨
- **ç®—æ³•åˆ†æ**ï¼šåˆ†æç®—æ³•é€»è¾‘å’Œå¤æ‚åº¦
- **æ¦‚å¿µè®²è§£**ï¼šè§£é‡Šæ¶‰åŠçš„ç¼–ç¨‹æ¦‚å¿µ
- **å¯è§†åŒ–**ï¼šé…åˆåŠ¨ç”»æ¼”ç¤º

##### å®ç°ç¤ºä¾‹

```javascript
// å‰ç«¯è°ƒç”¨ç¤ºä¾‹
async function explainCode(code) {
  const response = await fetch('/api/ai/explain-code', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ 
      code,
      language: 'python',
      detail_level: 'beginner' // beginner, intermediate, advanced
    })
  });
  
  const { explanation, concepts, visualization } = await response.json();
  return { explanation, concepts, visualization };
}
```

```python
# åç«¯å®ç°ç¤ºä¾‹ï¼ˆä½¿ç”¨ GPT-4ï¼‰
from openai import OpenAI

client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

def explain_code(code: str, language: str, detail_level: str):
    prompt = f"""
    è¯·è§£é‡Šä»¥ä¸‹ {language} ä»£ç ï¼Œè§£é‡Šè¯¦ç»†ç¨‹åº¦ï¼š{detail_level}ã€‚
    
    ä»£ç ï¼š
    ```{language}
    {code}
    ```
    
    è¯·æä¾›ï¼š
    1. æ•´ä½“åŠŸèƒ½æè¿°
    2. é€è¡Œè§£é‡Šï¼ˆå¯¹äºå¤æ‚ä»£ç ï¼‰
    3. æ¶‰åŠçš„ç¼–ç¨‹æ¦‚å¿µ
    4. æ—¶é—´å’Œç©ºé—´å¤æ‚åº¦ï¼ˆå¦‚é€‚ç”¨ï¼‰
    5. æ”¹è¿›å»ºè®®ï¼ˆå¦‚é€‚ç”¨ï¼‰
    """
    
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªç¼–ç¨‹æ•™è‚²ä¸“å®¶ï¼Œæ“…é•¿å‘åˆå­¦è€…è§£é‡Šä»£ç ã€‚"},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3
    )
    
    explanation = response.choices[0].message.content
    
    # æå–æ¦‚å¿µ
    concepts = extract_concepts(explanation)
    
    return {
        "explanation": explanation,
        "concepts": concepts,
        "visualization_suggestions": generate_visualization_hints(code)
    }
```

---

#### 3. æ™ºèƒ½çº é”™ï¼ˆError Detection & Fixingï¼‰

##### åŠŸèƒ½ç‰¹æ€§

- **è¯­æ³•é”™è¯¯æ£€æµ‹**ï¼šå®æ—¶æ£€æµ‹è¯­æ³•é”™è¯¯
- **é€»è¾‘é”™è¯¯æç¤º**ï¼šå‘ç°æ½œåœ¨é€»è¾‘é—®é¢˜
- **æ€§èƒ½é—®é¢˜è­¦å‘Š**ï¼šæ£€æµ‹ä½æ•ˆä»£ç 
- **ä¿®å¤å»ºè®®**ï¼šæä¾›ä¿®å¤æ–¹æ¡ˆ

##### å®ç°æ–¹æ¡ˆ

```python
# æ™ºèƒ½çº é”™ API
@app.post("/api/ai/fix-code")
async def fix_code(code: str, error_message: str):
    prompt = f"""
    å­¦ç”Ÿä»£ç ï¼š
    ```python
    {code}
    ```
    
    é”™è¯¯ä¿¡æ¯ï¼š
    {error_message}
    
    è¯·ï¼š
    1. åˆ†æé”™è¯¯åŸå› 
    2. æä¾›è¯¦ç»†çš„ä¿®å¤æ­¥éª¤
    3. ç»™å‡ºæ­£ç¡®çš„ä»£ç ç¤ºä¾‹
    4. è§£é‡Šå¦‚ä½•é¿å…ç±»ä¼¼é”™è¯¯
    
    æ³¨æ„ï¼šè¯·ä½¿ç”¨é€‚åˆåˆå­¦è€…çš„è¯­è¨€è¿›è¡Œè§£é‡Šã€‚
    """
    
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªè€å¿ƒçš„ç¼–ç¨‹è€å¸ˆã€‚"},
            {"role": "user", "content": prompt}
        ]
    )
    
    result = response.choices[0].message.content
    
    return {
        "analysis": extract_analysis(result),
        "fix_steps": extract_steps(result),
        "corrected_code": extract_code(result),
        "tips": extract_tips(result)
    }
```

---

#### 4. ä»£ç ä¼˜åŒ–å»ºè®®

##### åŠŸèƒ½

- **æ€§èƒ½ä¼˜åŒ–**ï¼šæå‡ä»£ç æ•ˆç‡
- **å¯è¯»æ€§ä¼˜åŒ–**ï¼šæ”¹å–„ä»£ç ç»“æ„
- **æœ€ä½³å®è·µ**ï¼šæ¨èç¼–ç è§„èŒƒ
- **å®‰å…¨å»ºè®®**ï¼šæ£€æµ‹å®‰å…¨éšæ‚£

##### å®ç°ç¤ºä¾‹

```python
def analyze_code_quality(code: str, language: str):
    # ä½¿ç”¨é™æ€åˆ†æå·¥å…·
    if language == 'python':
        import pylint
        # pylint åˆ†æ
        
    # ç»“åˆ AI åˆ†æ
    prompt = f"""
    åˆ†æä»¥ä¸‹ä»£ç çš„è´¨é‡ï¼Œä»ä»¥ä¸‹ç»´åº¦è¯„ä¼°ï¼š
    1. æ€§èƒ½ï¼ˆæ—¶é—´å¤æ‚åº¦ã€ç©ºé—´å¤æ‚åº¦ï¼‰
    2. å¯è¯»æ€§ï¼ˆå‘½åã€æ³¨é‡Šã€ç»“æ„ï¼‰
    3. å®‰å…¨æ€§
    4. æœ€ä½³å®è·µ
    
    ä»£ç ï¼š
    ```{language}
    {code}
    ```
    
    ç»™å‡ºè¯„åˆ†ï¼ˆ1-10ï¼‰å’Œå…·ä½“æ”¹è¿›å»ºè®®ã€‚
    """
    
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    
    return parse_analysis(response.choices[0].message.content)
```

---

## AI æ™ºèƒ½æ•™å­¦

### 1. ä¸ªæ€§åŒ–å­¦ä¹ è·¯å¾„

#### åŠŸèƒ½è®¾è®¡

- **èƒ½åŠ›è¯„ä¼°**ï¼šæµ‹è¯•å­¦ç”Ÿå½“å‰æ°´å¹³
- **ç›®æ ‡è®¾å®š**ï¼šæ ¹æ®å­¦ç”Ÿç›®æ ‡åˆ¶å®šè·¯å¾„
- **åŠ¨æ€è°ƒæ•´**ï¼šæ ¹æ®å­¦ä¹ è¿›åº¦å®æ—¶è°ƒæ•´
- **å¤šç»´åº¦æ¨è**ï¼šè¯¾ç¨‹ã€ç»ƒä¹ ã€é¡¹ç›®

#### å®ç°æ¶æ„

```
å­¦ç”Ÿç”»åƒ â†’ èƒ½åŠ›è¯„ä¼° â†’ è·¯å¾„ç”Ÿæˆ â†’ å­¦ä¹ æ¨è â†’ æ•ˆæœè¿½è¸ª â†’ è·¯å¾„ä¼˜åŒ–
```

#### ç®—æ³•æ¨¡å‹

**æ–¹æ¡ˆ Aï¼šåŸºäºè§„åˆ™çš„æ¨è**

```python
class LearningPathEngine:
    def __init__(self):
        self.knowledge_graph = self.load_knowledge_graph()
        
    def generate_path(self, student_profile):
        # 1. è¯„ä¼°å½“å‰æ°´å¹³
        current_level = self.assess_level(student_profile)
        
        # 2. è¯†åˆ«çŸ¥è¯†ç¼ºå£
        gaps = self.identify_gaps(current_level, student_profile.target)
        
        # 3. ç”Ÿæˆå­¦ä¹ è·¯å¾„
        path = []
        for gap in gaps:
            # æ‰¾åˆ°å¡«è¡¥è¯¥ç¼ºå£çš„è¯¾ç¨‹
            courses = self.find_courses_for_gap(gap)
            path.extend(courses)
            
        # 4. ä¼˜åŒ–é¡ºåºï¼ˆè€ƒè™‘å‰ç½®çŸ¥è¯†ï¼‰
        optimized_path = self.optimize_sequence(path)
        
        return optimized_path
```

**æ–¹æ¡ˆ Bï¼šAI é©±åŠ¨çš„æ¨è**

```python
# ä½¿ç”¨ LLM ç”Ÿæˆä¸ªæ€§åŒ–å­¦ä¹ è·¯å¾„
def generate_ai_learning_path(student_profile):
    prompt = f"""
    å­¦ç”Ÿä¿¡æ¯ï¼š
    - å¹´é¾„ï¼š{student_profile.age}
    - å½“å‰æ°´å¹³ï¼š{student_profile.current_level}
    - å­¦ä¹ ç›®æ ‡ï¼š{student_profile.goal}
    - å­¦ä¹ æ—¶é—´ï¼šæ¯å‘¨ {student_profile.hours_per_week} å°æ—¶
    - å…´è¶£æ–¹å‘ï¼š{student_profile.interests}
    - å­¦ä¹ å†å²ï¼š{student_profile.completed_courses}
    
    è¯·ä¸ºè¯¥å­¦ç”Ÿåˆ¶å®šä¸€ä¸ªä¸ºæœŸ 6 ä¸ªæœˆçš„ä¸ªæ€§åŒ–å­¦ä¹ è·¯å¾„ï¼ŒåŒ…æ‹¬ï¼š
    1. é˜¶æ®µåˆ’åˆ†
    2. æ¯ä¸ªé˜¶æ®µçš„å­¦ä¹ ç›®æ ‡
    3. æ¨èè¯¾ç¨‹å’Œèµ„æº
    4. å®è·µé¡¹ç›®
    5. è¯„ä¼°èŠ‚ç‚¹
    
    è¦æ±‚ï¼š
    - å¾ªåºæ¸è¿›ï¼Œéš¾åº¦é€‚ä¸­
    - ç†è®ºä¸å®è·µç»“åˆ
    - ä¿æŒå­¦ä¹ å…´è¶£
    """
    
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„æ•™è‚²è§„åˆ’å¸ˆã€‚"},
            {"role": "user", "content": prompt}
        ]
    )
    
    path = parse_learning_path(response.choices[0].message.content)
    return path
```

---

### 2. æ™ºèƒ½æ¨é¢˜ç³»ç»Ÿ

#### ç®—æ³•è®¾è®¡

##### åŸºäºçŸ¥è¯†ç‚¹çš„æ¨é¢˜

```python
class SmartProblemRecommender:
    def recommend(self, student_id):
        # 1. è·å–å­¦ç”ŸçŸ¥è¯†ç‚¹æŒæ¡æƒ…å†µ
        mastery = self.get_knowledge_mastery(student_id)
        
        # 2. è¯†åˆ«è–„å¼±çŸ¥è¯†ç‚¹
        weak_points = [kp for kp, score in mastery.items() if score < 0.6]
        
        # 3. ä¸ºæ¯ä¸ªè–„å¼±ç‚¹æ¨èé¢˜ç›®
        problems = []
        for kp in weak_points:
            # æ ¹æ®éš¾åº¦æ¢¯åº¦æ¨é¢˜
            difficulty = self.calculate_é€‚å½“éš¾åº¦(mastery[kp])
            problems.extend(
                self.get_problems(knowledge_point=kp, difficulty=difficulty, limit=3)
            )
            
        # 4. åŠ å…¥å·©å›ºé¢˜
        strong_points = [kp for kp, score in mastery.items() if score > 0.8]
        for kp in random.sample(strong_points, min(2, len(strong_points))):
            problems.append(self.get_problems(knowledge_point=kp, limit=1))
            
        return problems
```

##### åŸºäºååŒè¿‡æ»¤çš„æ¨é¢˜

```python
# ä½¿ç”¨ç›¸ä¼¼å­¦ç”Ÿçš„åšé¢˜æ•°æ®æ¨è
def collaborative_filtering_recommend(student_id):
    # 1. æ‰¾åˆ°ç›¸ä¼¼å­¦ç”Ÿ
    similar_students = find_similar_students(student_id, top_k=20)
    
    # 2. è·å–ä»–ä»¬åšè¿‡çš„é¢˜
    their_problems = get_solved_problems(similar_students)
    
    # 3. è¿‡æ»¤å­¦ç”Ÿå·²åšè¿‡çš„
    student_solved = get_solved_problems([student_id])
    candidate_problems = set(their_problems) - set(student_solved)
    
    # 4. æŒ‰ç…§ç›¸ä¼¼å­¦ç”Ÿçš„æ­£ç¡®ç‡æ’åº
    ranked_problems = rank_by_success_rate(candidate_problems, similar_students)
    
    return ranked_problems[:10]
```

##### åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ¨é¢˜

```python
# ä½¿ç”¨ RL ä¼˜åŒ–æ¨é¢˜ç­–ç•¥
class RLProblemRecommender:
    def __init__(self):
        self.model = self.load_rl_model()
        
    def recommend(self, student_state):
        # state: [çŸ¥è¯†ç‚¹æŒæ¡åº¦, æœ€è¿‘å­¦ä¹ æ—¶é•¿, æ­£ç¡®ç‡, ...]
        action = self.model.predict(student_state)
        # action: [é¢˜ç›®éš¾åº¦, çŸ¥è¯†ç‚¹, é¢˜ç›®ç±»å‹]
        
        problems = self.query_problems(action)
        return problems
        
    def update(self, student_id, recommended_problems, results):
        # æ ¹æ®å­¦ç”Ÿåšé¢˜ç»“æœæ›´æ–°æ¨¡å‹
        reward = self.calculate_reward(results)
        self.model.train(student_state, action, reward)
```

---

### 3. è‡ªåŠ¨æ‰¹æ”¹ç³»ç»Ÿ

#### ç¼–ç¨‹é¢˜è‡ªåŠ¨æ‰¹æ”¹

```python
# ä½¿ç”¨ä»£ç æ‰§è¡Œå¼•æ“ + AI è¯„ä»·
class AutoGrader:
    def grade_code(self, student_code, problem):
        # 1. è¯­æ³•æ£€æŸ¥
        syntax_ok, syntax_errors = self.check_syntax(student_code)
        if not syntax_ok:
            return {
                "score": 0,
                "errors": syntax_errors,
                "feedback": "ä»£ç å­˜åœ¨è¯­æ³•é”™è¯¯ï¼Œè¯·æ£€æŸ¥ã€‚"
            }
            
        # 2. è¿è¡Œæµ‹è¯•ç”¨ä¾‹
        test_results = self.run_tests(student_code, problem.test_cases)
        
        # 3. è®¡ç®—åˆ†æ•°
        score = sum([1 for r in test_results if r.passed]) / len(test_results) * 100
        
        # 4. AI ç”Ÿæˆåé¦ˆ
        if score < 100:
            feedback = self.generate_ai_feedback(
                code=student_code,
                test_results=test_results,
                problem_description=problem.description
            )
        else:
            feedback = "å®Œå…¨æ­£ç¡®ï¼" + self.generate_code_review(student_code)
            
        return {
            "score": score,
            "test_results": test_results,
            "feedback": feedback
        }
        
    def generate_ai_feedback(self, code, test_results, problem_description):
        failed_cases = [r for r in test_results if not r.passed]
        
        prompt = f"""
        å­¦ç”Ÿä»£ç ï¼š
        ```python
        {code}
        ```
        
        é¢˜ç›®æè¿°ï¼š{problem_description}
        
        å¤±è´¥çš„æµ‹è¯•ç”¨ä¾‹ï¼š
        {format_failed_cases(failed_cases)}
        
        è¯·æä¾›ï¼š
        1. é”™è¯¯åˆ†æ
        2. ä¿®å¤æç¤ºï¼ˆä¸è¦ç›´æ¥ç»™ç­”æ¡ˆï¼‰
        3. å­¦ä¹ å»ºè®®
        """
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        
        return response.choices[0].message.content
```

---

### 4. å­¦æƒ…åˆ†æç³»ç»Ÿ

#### æ•°æ®æ”¶é›†

```python
# å­¦ä¹ è¡Œä¸ºæ•°æ®
class LearningBehaviorTracker:
    def track(self, student_id, event):
        data = {
            "student_id": student_id,
            "timestamp": datetime.now(),
            "event_type": event.type,  # è§‚çœ‹è§†é¢‘ã€åšé¢˜ã€æäº¤ä»£ç ç­‰
            "event_data": event.data,
            "duration": event.duration,
            "result": event.result
        }
        self.save_to_db(data)
```

#### AI åˆ†æ

```python
# ä½¿ç”¨ ML æ¨¡å‹åˆ†æå­¦æƒ…
class LearningAnalyzer:
    def analyze_student(self, student_id):
        # 1. è·å–å­¦ä¹ æ•°æ®
        data = self.get_learning_data(student_id, days=30)
        
        # 2. è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        stats = {
            "total_time": sum([d.duration for d in data]),
            "completion_rate": self.calculate_completion_rate(data),
            "avg_score": self.calculate_avg_score(data),
            "active_days": len(set([d.date for d in data])),
            "knowledge_mastery": self.calculate_knowledge_mastery(data)
        }
        
        # 3. AI ç”Ÿæˆåˆ†ææŠ¥å‘Š
        report = self.generate_ai_report(student_id, stats, data)
        
        # 4. é¢„æµ‹å­¦ä¹ é£é™©
        risk_level = self.predict_risk(data)
        
        # 5. ç”Ÿæˆå»ºè®®
        suggestions = self.generate_suggestions(stats, risk_level)
        
        return {
            "stats": stats,
            "report": report,
            "risk_level": risk_level,
            "suggestions": suggestions
        }
        
    def generate_ai_report(self, student_id, stats, data):
        prompt = f"""
        å­¦ç”Ÿå­¦ä¹ æ•°æ®åˆ†æï¼š
        
        ç»Ÿè®¡æ•°æ®ï¼š
        - å­¦ä¹ æ—¶é•¿ï¼š{stats['total_time']} åˆ†é’Ÿ
        - å®Œæˆç‡ï¼š{stats['completion_rate']}%
        - å¹³å‡åˆ†ï¼š{stats['avg_score']}
        - æ´»è·ƒå¤©æ•°ï¼š{stats['active_days']}
        - çŸ¥è¯†ç‚¹æŒæ¡ï¼š{stats['knowledge_mastery']}
        
        è¯¦ç»†è¡Œä¸ºæ•°æ®ï¼š
        {format_learning_data(data)}
        
        è¯·æä¾›ï¼š
        1. å­¦ä¹ çŠ¶æ€è¯„ä»·
        2. ä¼˜åŠ¿å’Œä¸è¶³
        3. å­¦ä¹ ä¹ æƒ¯åˆ†æ
        4. æ”¹è¿›å»ºè®®
        5. é£é™©é¢„è­¦ï¼ˆå¦‚æœ‰ï¼‰
        """
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        
        return response.choices[0].message.content
```

---

### 5. è™šæ‹ŸåŠ©æ•™ï¼ˆAI Tutorï¼‰

#### åŠŸèƒ½è®¾è®¡

- **24/7 åœ¨çº¿ç­”ç–‘**
- **ä¸ªæ€§åŒ–è¾…å¯¼**
- **å­¦ä¹ é™ªä¼´**
- **æƒ…æ„Ÿæ”¯æŒ**

#### å®ç°æ–¹æ¡ˆ

```python
# AI è™šæ‹ŸåŠ©æ•™
class AITutor:
    def __init__(self, student_id):
        self.student_id = student_id
        self.conversation_history = []
        self.student_context = self.load_student_context(student_id)
        
    async def chat(self, user_message):
        # 1. ç†è§£æ„å›¾
        intent = self.classify_intent(user_message)
        
        # 2. æ ¹æ®æ„å›¾å¤„ç†
        if intent == "ask_concept":
            response = await self.explain_concept(user_message)
        elif intent == "ask_code_help":
            response = await self.help_with_code(user_message)
        elif intent == "ask_problem_hint":
            response = await self.give_hint(user_message)
        else:
            response = await self.general_chat(user_message)
            
        # 3. è®°å½•å¯¹è¯
        self.conversation_history.append({
            "role": "user",
            "content": user_message
        })
        self.conversation_history.append({
            "role": "assistant",
            "content": response
        })
        
        return response
        
    async def explain_concept(self, question):
        # æ„å»º promptï¼ŒåŒ…å«å­¦ç”Ÿä¸Šä¸‹æ–‡
        prompt = f"""
        å­¦ç”ŸèƒŒæ™¯ï¼š
        - å¹´é¾„ï¼š{self.student_context.age}
        - ç¼–ç¨‹æ°´å¹³ï¼š{self.student_context.level}
        - æœ€è¿‘å­¦ä¹ å†…å®¹ï¼š{self.student_context.recent_topics}
        
        å­¦ç”Ÿé—®é¢˜ï¼š{question}
        
        è¯·ç”¨é€‚åˆè¯¥å­¦ç”Ÿçš„è¯­è¨€è§£é‡Šï¼ŒåŒ…æ‹¬ï¼š
        1. æ¦‚å¿µå®šä¹‰
        2. ä¸ºä»€ä¹ˆé‡è¦
        3. ç®€å•ç¤ºä¾‹
        4. å®è·µåº”ç”¨
        5. ç›¸å…³èµ„æº
        """
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªè€å¿ƒã€å‹å¥½çš„ç¼–ç¨‹è€å¸ˆã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )
        
        return response.choices[0].message.content
        
    async def give_hint(self, user_message):
        # è¯†åˆ«å­¦ç”Ÿæ­£åœ¨åšçš„é¢˜ç›®
        current_problem = self.student_context.current_problem
        
        prompt = f"""
        é¢˜ç›®ï¼š{current_problem.description}
        
        å­¦ç”Ÿè¯¢é—®ï¼š{user_message}
        
        å­¦ç”Ÿä»£ç ï¼ˆå¦‚æœ‰ï¼‰ï¼š
        ```python
        {self.student_context.current_code}
        ```
        
        è¯·æä¾›æç¤ºï¼Œè¦æ±‚ï¼š
        1. ä¸è¦ç›´æ¥ç»™å‡ºç­”æ¡ˆ
        2. å¼•å¯¼å­¦ç”Ÿæ€è€ƒ
        3. æç¤ºå…³é”®æ€è·¯
        4. é¼“åŠ±å­¦ç”Ÿè‡ªå·±è§£å†³
        """
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        
        return response.choices[0].message.content
```

---

## AI å†…å®¹ç”Ÿæˆ

### 1. AI ç”Ÿæˆæ•™æ¡ˆ

```python
def generate_lesson_plan(topic, target_audience, duration):
    prompt = f"""
    è¯·ä¸ºä»¥ä¸‹ä¸»é¢˜ç”Ÿæˆä¸€ä»½è¯¦ç»†çš„æ•™æ¡ˆï¼š
    
    ä¸»é¢˜ï¼š{topic}
    ç›®æ ‡å—ä¼—ï¼š{target_audience}
    æ—¶é•¿ï¼š{duration} åˆ†é’Ÿ
    
    æ•™æ¡ˆåº”åŒ…æ‹¬ï¼š
    1. å­¦ä¹ ç›®æ ‡
    2. æ•™å­¦å†…å®¹å¤§çº²
    3. æ•™å­¦æ–¹æ³•å’Œæ´»åŠ¨
    4. äº’åŠ¨ç¯èŠ‚è®¾è®¡
    5. ç»ƒä¹ é¢˜
    6. è¯„ä¼°æ–¹å¼
    7. è¯¾åä½œä¸š
    8. æ‹“å±•èµ„æº
    
    è¦æ±‚ï¼š
    - é€‚åˆç›®æ ‡å—ä¼—çš„è®¤çŸ¥æ°´å¹³
    - ç†è®ºä¸å®è·µç»“åˆ
    - äº’åŠ¨æ€§å¼º
    - æœ‰è¶£å‘³æ€§
    """
    
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7
    )
    
    return response.choices[0].message.content
```

### 2. AI ç”Ÿæˆç»ƒä¹ é¢˜

```python
def generate_practice_problems(knowledge_point, difficulty, count):
    prompt = f"""
    è¯·ç”Ÿæˆ {count} é“å…³äº "{knowledge_point}" çš„ç¼–ç¨‹ç»ƒä¹ é¢˜ã€‚
    
    è¦æ±‚ï¼š
    - éš¾åº¦ï¼š{difficulty}ï¼ˆç®€å•/ä¸­ç­‰/å›°éš¾ï¼‰
    - æ¯é¢˜åŒ…æ‹¬ï¼š
      1. é¢˜ç›®æè¿°
      2. è¾“å…¥è¾“å‡ºæ ¼å¼
      3. æ ·ä¾‹æ•°æ®
      4. æç¤º
      5. å‚è€ƒç­”æ¡ˆ
      6. æµ‹è¯•ç”¨ä¾‹ï¼ˆè‡³å°‘ 5 ä¸ªï¼‰
    
    é¢˜ç›®åº”ï¼š
    - æœ‰å®é™…æ„ä¹‰
    - æœ‰è¶£å‘³æ€§
    - éš¾åº¦é€’è¿›
    """
    
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    
    problems = parse_problems(response.choices[0].message.content)
    return problems
```

### 3. AI ç”Ÿæˆé¡¹ç›®åˆ›æ„

```python
def generate_project_ideas(student_profile):
    prompt = f"""
    ä¸ºå­¦ç”Ÿç”Ÿæˆ 5 ä¸ªé€‚åˆçš„ç¼–ç¨‹é¡¹ç›®åˆ›æ„ï¼š
    
    å­¦ç”Ÿä¿¡æ¯ï¼š
    - å¹´é¾„ï¼š{student_profile.age}
    - ç¼–ç¨‹æ°´å¹³ï¼š{student_profile.level}
    - å…´è¶£ï¼š{student_profile.interests}
    - å·²æŒæ¡æŠ€èƒ½ï¼š{student_profile.skills}
    
    æ¯ä¸ªé¡¹ç›®åº”åŒ…æ‹¬ï¼š
    1. é¡¹ç›®åç§°
    2. ç®€ä»‹
    3. å­¦ä¹ ç›®æ ‡
    4. æŠ€æœ¯æ ˆ
    5. éš¾åº¦è¯„ä¼°
    6. é¢„ä¼°æ—¶é—´
    7. å®ç°æ­¥éª¤ï¼ˆå¤§çº²ï¼‰
    8. æ‰©å±•æ–¹å‘
    
    è¦æ±‚ï¼š
    - æœ‰è¶£ã€æœ‰åˆ›æ„
    - éš¾åº¦é€‚ä¸­
    - å®ç”¨æ€§å¼º
    - èƒ½å±•ç¤ºæŠ€èƒ½
    """
    
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    
    return response.choices[0].message.content
```

---

## AI æ¨¡å‹è®­ç»ƒå¹³å°

### åŠŸèƒ½è®¾è®¡

#### 1. æ— ä»£ç æ¨¡å‹è®­ç»ƒ

```
æ•°æ®ä¸Šä¼  â†’ æ•°æ®æ ‡æ³¨ â†’ æ¨¡å‹é€‰æ‹© â†’ è®­ç»ƒé…ç½® â†’ å¼€å§‹è®­ç»ƒ â†’ è¯„ä¼° â†’ éƒ¨ç½²
```

#### 2. å‰ç«¯ç•Œé¢

```javascript
// React ç»„ä»¶ç¤ºä¾‹
function ModelTrainingPlatform() {
  const [step, setStep] = useState('upload');
  const [dataset, setDataset] = useState(null);
  const [model, setModel] = useState(null);
  const [trainingStatus, setTrainingStatus] = useState(null);
  
  return (
    <div className="training-platform">
      {step === 'upload' && (
        <DatasetUpload onUpload={(data) => {
          setDataset(data);
          setStep('label');
        }} />
      )}
      
      {step === 'label' && (
        <DataLabeling 
          dataset={dataset}
          onComplete={() => setStep('selectModel')}
        />
      )}
      
      {step === 'selectModel' && (
        <ModelSelector
          taskType={dataset.taskType}
          onSelect={(selectedModel) => {
            setModel(selectedModel);
            setStep('configure');
          }}
        />
      )}
      
      {step === 'configure' && (
        <TrainingConfig
          model={model}
          dataset={dataset}
          onStart={(config) => {
            startTraining(config);
            setStep('training');
          }}
        />
      )}
      
      {step === 'training' && (
        <TrainingMonitor 
          status={trainingStatus}
          onComplete={() => setStep('evaluate')}
        />
      )}
      
      {step === 'evaluate' && (
        <ModelEvaluation
          model={model}
          dataset={dataset}
          onDeploy={() => deployModel(model)}
        />
      )}
    </div>
  );
}
```

#### 3. åç«¯è®­ç»ƒæœåŠ¡

```python
# FastAPI è®­ç»ƒæœåŠ¡
from fastapi import FastAPI, UploadFile
from celery import Celery

app = FastAPI()
celery_app = Celery('tasks', broker='redis://localhost:6379')

@app.post("/api/train/start")
async def start_training(config: TrainingConfig):
    # å¼‚æ­¥å¯åŠ¨è®­ç»ƒä»»åŠ¡
    task = celery_app.send_task(
        'train_model',
        args=[config.dict()]
    )
    
    return {"task_id": task.id}

@celery_app.task
def train_model(config):
    import tensorflow as tf
    
    # 1. åŠ è½½æ•°æ®
    dataset = load_dataset(config['dataset_id'])
    
    # 2. æ„å»ºæ¨¡å‹
    if config['model_type'] == 'image_classification':
        model = build_cnn_model(
            input_shape=config['input_shape'],
            num_classes=config['num_classes']
        )
    
    # 3. è®­ç»ƒ
    history = model.fit(
        dataset.train,
        validation_data=dataset.val,
        epochs=config['epochs'],
        callbacks=[
            TrainingProgressCallback(task.id),
            EarlyStopping(patience=5)
        ]
    )
    
    # 4. ä¿å­˜æ¨¡å‹
    model.save(f'models/{task.id}.h5')
    
    # 5. è¯„ä¼°
    metrics = model.evaluate(dataset.test)
    
    return {
        "model_id": task.id,
        "metrics": metrics,
        "history": history.history
    }
```

---

## AI èƒ½åŠ›è¯„ä¼°

### å¤šç»´åº¦èƒ½åŠ›ç”»åƒ

```python
class StudentAbilityProfile:
    def generate_profile(self, student_id):
        # 1. æ”¶é›†æ•°æ®
        data = {
            "coding_data": self.get_coding_data(student_id),
            "learning_data": self.get_learning_data(student_id),
            "project_data": self.get_project_data(student_id),
            "ai_data": self.get_ai_practice_data(student_id)
        }
        
        # 2. è®¡ç®—å„ç»´åº¦èƒ½åŠ›
        abilities = {
            "ç¼–ç¨‹åŸºç¡€": self.assess_coding_foundation(data),
            "ç®—æ³•æ€ç»´": self.assess_algorithm_thinking(data),
            "å·¥ç¨‹èƒ½åŠ›": self.assess_engineering_ability(data),
            "AI ç´ å…»": self.assess_ai_literacy(data),
            "åˆ›æ–°èƒ½åŠ›": self.assess_creativity(data),
            "å­¦ä¹ èƒ½åŠ›": self.assess_learning_ability(data)
        }
        
        # 3. AI ç”Ÿæˆç»¼åˆè¯„ä»·
        comprehensive_evaluation = self.generate_ai_evaluation(abilities, data)
        
        # 4. ç”Ÿæˆå¯è§†åŒ–
        visualization = self.create_radar_chart(abilities)
        
        return {
            "abilities": abilities,
            "evaluation": comprehensive_evaluation,
            "visualization": visualization,
            "recommendations": self.generate_recommendations(abilities)
        }
```

---

## æŠ€æœ¯å®ç°æ–¹æ¡ˆ

### æ–¹æ¡ˆå¯¹æ¯”

| åŠŸèƒ½ | è‡ªç ”æ¨¡å‹ | å¼€æºæ¨¡å‹ | ç¬¬ä¸‰æ–¹ API |
|------|---------|---------|------------|
| **ä»£ç è¡¥å…¨** | æˆæœ¬é«˜ | â­ StarCoder | GitHub Copilot |
| **ä»£ç è§£é‡Š** | - | - | â­ GPT-4 |
| **å¯¹è¯ç³»ç»Ÿ** | æˆæœ¬é«˜ | â­ LLaMA 2 | GPT-4 / Claude |
| **å›¾åƒè¯†åˆ«** | â­ å¯æ§ | YOLO / ResNet | Google Vision API |
| **å†…å®¹ç”Ÿæˆ** | - | Stable Diffusion | â­ GPT-4 / DALLÂ·E |

### æ¨èæŠ€æœ¯æ ˆ

#### å‰ç«¯
- React / Vue 3
- TensorFlow.jsï¼ˆæµè§ˆå™¨ç«¯ MLï¼‰
- Monaco Editorï¼ˆä»£ç ç¼–è¾‘ï¼‰
- EChartsï¼ˆæ•°æ®å¯è§†åŒ–ï¼‰

#### åç«¯
- Python + FastAPI
- TensorFlow / PyTorch
- Celeryï¼ˆå¼‚æ­¥ä»»åŠ¡ï¼‰
- Redisï¼ˆç¼“å­˜ï¼‰
- PostgreSQL + å‘é‡æ•°æ®åº“

#### AI æœåŠ¡
- OpenAI APIï¼ˆGPT-4ï¼‰
- Hugging Face Transformers
- è‡ªéƒ¨ç½²å¼€æºæ¨¡å‹ï¼ˆGPU æœåŠ¡å™¨ï¼‰

#### åŸºç¡€è®¾æ–½
- Docker + Kubernetes
- GPU é›†ç¾¤
- å¯¹è±¡å­˜å‚¨ï¼ˆæ¨¡å‹ã€æ•°æ®é›†ï¼‰
- ç›‘æ§å’Œæ—¥å¿—

---

ğŸ“ æœ€åæ›´æ–°ï¼š2025-11-13
